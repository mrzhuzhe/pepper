## Hacking the kidney 

## 为什么

1. 为什么什么大tiff图片要切片才能训练？ To make such large images to be suitable for training of a neural network, they must be cut into tiles. 

ans：因为有老外在历史比赛中测试了小切片不影响整体的泛化性能，甚至可以shift切片还能增加泛化性能

2. 为什么efficientnet 要选择 b0 - b7 有什么区别？

ans: 对应不同图片分辨率，依次加大

3. 为什么linknet 似乎比 unet 表现好？

ans: 虽然模注意力的linknet 比unet训练快很多，但是分数似乎差不多

4. 用什么损失度量比较好 bce_jacobian 为什么比交叉熵好？

ans： 这个还没测好，调参太麻烦了

5. 现有模型似乎严重过拟合，是否可以优化学习曲线（可以参考俄国佬的方案）？

ans: 从学习曲线看似乎进了次优解

6. 为什么要读论文？

ans：提升上限，还要看顶会

7. 如何做 本地cv 验证？ fold是用来做本地cv验证的吗？

ans: 是的，数据越多效果越好

8. 是不是多边形标注的方式上也可以优化

ans: 这个方案很多论文有提到，但是论坛里却没有被提到过

9. 架构层面优化从哪些方面入手

ans: 逐层训练，优化器，批归一化，损失函数等，这块太难了，还没有找到突破口

10. 如何分析性能瓶颈

ans: tensorboard 自定义打log


## 实验记录

|  版本号   | 变量  | 分数 | 效果 | 类型 | 目的 | 结论 |
|  ---- | ---- | ---- | ----- | ---- | ----- | ---- |
|  1  | efficientnet4  | 时间13ks  | 自己验证平均分9.17 提交分 9.07 | unet | 初始化 | 初始化 |
|  2  | batchsize 16 加倍 | 时间15ks  | 自己验证平均分9.22 提交分 9.07 | unet | batch size 加倍 | 时间还变长了 |
|  3  | linknet batch 16 bce_jaccard_loss efficientnet0 | 时间8ks  | 自己验证平均分9.17 提交分 9.15 | link | 换其他模型| 换loss 减小effnet|
|  4  | 换回 unet bce_jaccard_loss efficientnet0 | 时间8ks  | 自己验证平均分9.17 提交分 9.15 | unet | 减少efficeintnet | 没影响 提交时threahold的影响 |
|  5  | 增加了随机颜色 噪声等自增 | 时间11ks  | 自己验证平均分9.07 提交分 8.8 | unet | 数据自增 | 增加噪声会大幅增加时间 |
|  6  | 图片换为256 | 时间3ks  | 自己验证平均分9.04 未提交 | unet | 增加数据 | 图像减小大幅提升速度 |
|  7  | 去掉噪声自增 | 时间3ks  | 自己验证平均分9.09 未提交 | unet | 减少影响精度的噪声 | 似乎图像自增会影响精度 |
|  8  | 修改左右反转的概率 | 时间3ks  | 自己验证平均分9.12 未提交 | unet | 似乎存在+-.03的波动 | |
|  9  | batch增大四倍 epoch加倍 | 时间2.5ks  | 自己验证平均分9.31 提交9.18 | unet | 增加噪声后似乎没收敛？ | batch 是否有影响？ |
|  10  | 直接转为linknet | 时间2.2ks  | 自己验证平均分9.0 未提交 这个版本偏差极大 有一个.81的极低分 | link | batch加大似乎引起了高方差 |  |
|  11  | linknet 学习率加大 增加lookahead | 时间3.5ks  | 自己验证平均分9.2 未提交 有一个.86的极低分  | link | 不清楚是lookahead还是学习率的影响 |  |
|  12  | 修复seed的bug | 时间3.5ks  | 自己验证平均分9.19 未提交 有一个.88的极低分  | link | 没有每次改变数据顺序 | 似乎shuff没影响？ |
|  13  | batch 和学习率还原 删除精确度的metrics |   |   | link | 还原参照物，现在只需要看lookahead和其他项目的影响了 | 这个版本cv只有9.11 但是提交上去却有9.17 |
|  14  | 还原为unet，去掉lookahead |  时间3ks |   | unet | 反复调整参数寻找最优学习率 | 目前最优学习率是1e-3到1e-4之间 大于或小于这个区间都会导致误差增大 cv9.31 lb9.18 |
|  15  | backbone改为b2（version43） |  时间6ks |   | unet | backbone和图片分辨率有关 | cv9.31 lb9.20 |
|  16  | 尝试用gpu训练 |  时间超过9小时 |   | unet | batchsize只能设置为32 | 超时报错 |
|  17  | `尝试使用tensorboard` |   |   | unet | tpu下tensorboard需要单独打log | 直接开启tensorboard会报错 |
|  18  | 使用tta |   |   | infer阶段 | 上下 左右翻转 旋转180度 | lb9.20 - lb9.21 |
|  19  | loss函数换为bce |   |   | unet | 学习率1e-3时 cv8.9 5e-4cv9.0 | 还需要继续调整参数 |
|  20  | 使用外部数据（version54） |   |   | unet | 增加了手工标注的外部数据 cv9.31 lb9.24 | dataset链接：https://www.kaggle.com/baesiann/glomeruli-hubmap-external-1024x1024 论坛里maxwell找到了一篇训练数据对医疗结果影响的体系化说明的论文 |


## 结论

|  因素   | 变量  | 影响 | 现象 | 结论 |
|  ---- | ---- | ---- | ----- | ---- |
|  多折验证 | ---- | 提升泛化 | ----- | 训练出多个模型预测时平均 |
|  数据自增 | 几盒变换，颜色变换 | 提升泛化 | cv降低lb增高 | ---- |
|  batch大小 | size 32 - 128 | ---- | 1. 大size训练快 2.小size泛化性更好（有争议） | ---- |
|  学习率 | ---- | 影响最大的超参数 | 1.和loss函数有关 2.和batchsize有关 | 需要调至最优，需要设置衰减 |
|  数据打乱顺序 | ---- | ---- | cv更接近lb | ---- |
|  文件大小 | ---- | ---- | 文件降质，可大幅提升训练速度 | ---- |
|  efficientnet容量 | b0-b7 | 对应输入图片的分辨率和卷积大小 | b2的训练时间比b0多了百分之六十左右，但是分数会增加不少 | ---- |
|  TTA测试环节自增 | 几何变换 | 似乎能提升泛化性能 | 是一种模型融合手段，微量提升泛化能力，可能跟loss函数的选取有关 | ---- |
|  `架构-损失函数` | ---- | 历史竞赛里都定制了损失函数 | ----- | ---- |
|  架构-不同backbone | ---- | ---- | ----- | ---- |
|  架构-不同优化器 | ---- | ---- | ----- | ---- |
|  预处理-数据清洗 | ---- | 消除错误标注 | ----- | ---- |
|  预处理-预采样 | ---- | deepflash | ----- | ---- |
|  `针对性外部数据` | ---- | 似乎可以极大提升分数 | ----- | ---- |
|  `badcase可视化分析` | ---- | ---- | ----- | ---- |

特别的因素：外部数据 和 手工标注

很没技术含量的方案，但是有老外总结了不同类型的外部数据对结果的影响发过论文，还有人分析过针对性的badcase做的特殊数据会对结果有极大提升